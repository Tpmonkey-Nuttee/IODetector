{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IODetector for Thai Langauge",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Iauez2yN7_Qhy9RSZWoSjpZXtH_AVLEk",
      "authorship_tag": "ABX9TyMd8I80x0BT/vvIDKTbAj55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tpmonkey-Nuttee/IODetector/blob/main/IODetector_for_Thai_Langauge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhjcN-ZDqoM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842f24ab-3e16-433c-fcd5-5b5145f335ed"
      },
      "source": [
        "!pip install pythainlp\n",
        "!pip install stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (0.9.7)\n",
            "Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (4.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl6eS5QDubUp"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-cdOrnqtxu3"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87dUsJsYPeDa"
      },
      "source": [
        "## Spam Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "OONxmGfRIyvY",
        "outputId": "8c7af9cd-027d-42c5-efad-a92bb6028bf6"
      },
      "source": [
        "# Load data from GoogleDrive\n",
        "# Dataset can be found at: https://transparency.twitter.com/en/reports/information-operations.html\n",
        "df1 = pd.read_csv(\"drive/MyDrive/FastAI/thailand_092020_tweets_csv_hashed.csv\")\n",
        "\n",
        "# We only care about tweet itself, nothing else.\n",
        "df1 = df1[['tweet_text']]\n",
        "df1.columns = ['text']\n",
        "\n",
        "# Drop row so it matchs with ham dataset to prevent imbalance dataset.\n",
        "df1.drop( df1.index[4800:], 0, inplace = True )\n",
        "\n",
        "# Set the classification value, We will use it as a label.\n",
        "df1['is_spam'] = 1 \n",
        "\n",
        "\n",
        "df1.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>กกต.จี้“อนาคตใหม่”แจงเงินกู้“ธนาธร” https://t....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ตายสนิท!'อิศรา'เปิดภ.ง.ด.91ปี61'คุณช่อ'แจ้งราย...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let's Get It : ชีวิตติดใบแดง CD กันต์ธีร์  EP....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>อ้าวเฮ้ย ไม่เหมือนที่คุยกันไว้นี่หว่า...อุตส่า...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เป้นกำลังใจให้นะท่าน</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4794</th>\n",
              "      <td>RT @army2pr: ข้ามแดนนครพนมปลอดภัย หมอทหารใส่ใจ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>RT @army2pr: \"จะมองผ่านเลนส์..หรือ..มองผ่านตา....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>RT @army2pr: “มทบ.24 จัดกำลังพลร่วมบริจาคโลหิต...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>RT @army2pr: “แม่ทัพห่วงใยส่งผู้แทนเยี่ยมตำรวจ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>RT @army2pr: วิธีป้องกันตนเองจากเชื้อไวรัสโคโร...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4799 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  is_spam\n",
              "0     กกต.จี้“อนาคตใหม่”แจงเงินกู้“ธนาธร” https://t....        1\n",
              "1     ตายสนิท!'อิศรา'เปิดภ.ง.ด.91ปี61'คุณช่อ'แจ้งราย...        1\n",
              "2     Let's Get It : ชีวิตติดใบแดง CD กันต์ธีร์  EP....        1\n",
              "3     อ้าวเฮ้ย ไม่เหมือนที่คุยกันไว้นี่หว่า...อุตส่า...        1\n",
              "4                                  เป้นกำลังใจให้นะท่าน        1\n",
              "...                                                 ...      ...\n",
              "4794  RT @army2pr: ข้ามแดนนครพนมปลอดภัย หมอทหารใส่ใจ...        1\n",
              "4795  RT @army2pr: \"จะมองผ่านเลนส์..หรือ..มองผ่านตา....        1\n",
              "4796  RT @army2pr: “มทบ.24 จัดกำลังพลร่วมบริจาคโลหิต...        1\n",
              "4797  RT @army2pr: “แม่ทัพห่วงใยส่งผู้แทนเยี่ยมตำรวจ...        1\n",
              "4798  RT @army2pr: วิธีป้องกันตนเองจากเชื้อไวรัสโคโร...        1\n",
              "\n",
              "[4799 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VLqtb8xRMQp"
      },
      "source": [
        "## Ham Dataset\n",
        "Ham in this case means \"Normal Message\" (not the ham that you eat)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "xp7jE5TVNa3D",
        "outputId": "4ab5cd56-283a-46d1-9790-49f00ca7e3c5"
      },
      "source": [
        "# This is a translate version of this spam detection dataset https://www.kaggle.com/benvozza/spam-classification\n",
        "# I grab only ham messages and translated it using pythainlp translator.\n",
        "# And save it as a file in Google Drive\n",
        "df2 = pd.read_csv('drive/MyDrive/FastAI/ham_th.csv')\n",
        "\n",
        "# Delete unwanted colums, So it matchs with the Spam Dataset\n",
        "del df2['Unnamed: 0']\n",
        "del df2['text']\n",
        "df2.columns = ['text', 'is_spam']\n",
        "\n",
        "df2.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ไปจนถึงจูรงพ้อยท์ บ้า...มีขายเฉพาะในบูกิสและโล...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>โอเค....ล้อเล่นกับเธอนะ โอนิ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>เธอไม่บอกเร็วนักเหรอ...เธอเห็นแล้วค่อยบอก...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ไม่ ฉันไม่คิดว่าเขาไปที่ยูเอสเอฟนะ เขาอาศัยอยู...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>แม้แต่พี่ชายของฉันก็ไม่ชอบคุยกับฉัน พวกเขาปฏิบ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4819</th>\n",
              "      <td>ทําไมคุณไม่รอจนกว่าอย่างน้อยวันพุธเพื่อดูว่าคุ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>ฮะ ทําไมละ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4821</th>\n",
              "      <td>เธอจะไปที่ห้างเอสพลานาดจากบ้านไหมอ่ะ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>น่าเสียดาย, * อยู่ในอารมณ์นั้น มีอะไรแนะนําอีก...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4823</th>\n",
              "      <td>ผู้ชายคนนี้ทําตัวน่ารําคาญ แต่ฉันทําเหมือนฉันจ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4824 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  is_spam\n",
              "0     ไปจนถึงจูรงพ้อยท์ บ้า...มีขายเฉพาะในบูกิสและโล...        0\n",
              "1                       โอเค....ล้อเล่นกับเธอนะ โอนิ...        0\n",
              "2          เธอไม่บอกเร็วนักเหรอ...เธอเห็นแล้วค่อยบอก...        0\n",
              "3     ไม่ ฉันไม่คิดว่าเขาไปที่ยูเอสเอฟนะ เขาอาศัยอยู...        0\n",
              "4     แม้แต่พี่ชายของฉันก็ไม่ชอบคุยกับฉัน พวกเขาปฏิบ...        0\n",
              "...                                                 ...      ...\n",
              "4819  ทําไมคุณไม่รอจนกว่าอย่างน้อยวันพุธเพื่อดูว่าคุ...        0\n",
              "4820                                      ฮะ ทําไมละ...        0\n",
              "4821               เธอจะไปที่ห้างเอสพลานาดจากบ้านไหมอ่ะ        0\n",
              "4822  น่าเสียดาย, * อยู่ในอารมณ์นั้น มีอะไรแนะนําอีก...        0\n",
              "4823  ผู้ชายคนนี้ทําตัวน่ารําคาญ แต่ฉันทําเหมือนฉันจ...        0\n",
              "\n",
              "[4824 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJnFKaGkR2Rw"
      },
      "source": [
        "## Final Dataset and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "AUlECJMcR3dj",
        "outputId": "9777a8e3-1525-41fc-9d9b-11f8d24cdf1e"
      },
      "source": [
        "# Merge it together\n",
        "df = pd.concat([df1, df2])\n",
        "\n",
        "df.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>กกต.จี้“อนาคตใหม่”แจงเงินกู้“ธนาธร” https://t....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ตายสนิท!'อิศรา'เปิดภ.ง.ด.91ปี61'คุณช่อ'แจ้งราย...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let's Get It : ชีวิตติดใบแดง CD กันต์ธีร์  EP....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>อ้าวเฮ้ย ไม่เหมือนที่คุยกันไว้นี่หว่า...อุตส่า...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เป้นกำลังใจให้นะท่าน</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4819</th>\n",
              "      <td>ทําไมคุณไม่รอจนกว่าอย่างน้อยวันพุธเพื่อดูว่าคุ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>ฮะ ทําไมละ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4821</th>\n",
              "      <td>เธอจะไปที่ห้างเอสพลานาดจากบ้านไหมอ่ะ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>น่าเสียดาย, * อยู่ในอารมณ์นั้น มีอะไรแนะนําอีก...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4823</th>\n",
              "      <td>ผู้ชายคนนี้ทําตัวน่ารําคาญ แต่ฉันทําเหมือนฉันจ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9624 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  is_spam\n",
              "0     กกต.จี้“อนาคตใหม่”แจงเงินกู้“ธนาธร” https://t....        1\n",
              "1     ตายสนิท!'อิศรา'เปิดภ.ง.ด.91ปี61'คุณช่อ'แจ้งราย...        1\n",
              "2     Let's Get It : ชีวิตติดใบแดง CD กันต์ธีร์  EP....        1\n",
              "3     อ้าวเฮ้ย ไม่เหมือนที่คุยกันไว้นี่หว่า...อุตส่า...        1\n",
              "4                                  เป้นกำลังใจให้นะท่าน        1\n",
              "...                                                 ...      ...\n",
              "4819  ทําไมคุณไม่รอจนกว่าอย่างน้อยวันพุธเพื่อดูว่าคุ...        0\n",
              "4820                                      ฮะ ทําไมละ...        0\n",
              "4821               เธอจะไปที่ห้างเอสพลานาดจากบ้านไหมอ่ะ        0\n",
              "4822  น่าเสียดาย, * อยู่ในอารมณ์นั้น มีอะไรแนะนําอีก...        0\n",
              "4823  ผู้ชายคนนี้ทําตัวน่ารําคาญ แต่ฉันทําเหมือนฉันจ...        0\n",
              "\n",
              "[9624 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6onRKlSEuwbW"
      },
      "source": [
        "import re\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wow9bUdEWL1h"
      },
      "source": [
        "# possible emoji pattern, We use this to remove all the emoji in tweet text.\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "  u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "  u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "  u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "  u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "  u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "  u\"\\U00002702-\\U000027B0\"\n",
        "  u\"\\U00002702-\\U000027B0\"\n",
        "  u\"\\U000024C2-\\U0001F251\"\n",
        "  u\"\\U0001f926-\\U0001f937\"\n",
        "  u\"\\U00010000-\\U0010ffff\"\n",
        "  u\"\\u2640-\\u2642\"\n",
        "  u\"\\u2600-\\u2B55\"\n",
        "  u\"\\u200d\"\n",
        "  u\"\\u23cf\"\n",
        "  u\"\\u23e9\"\n",
        "  u\"\\u231a\"\n",
        "  u\"\\ufe0f\"  # dingbats\n",
        "  u\"\\u3030\"\n",
        "  \"]+\", flags=re.UNICODE)\n",
        "\n",
        "# Replace all emoji with \"\"\n",
        "def remove_emoji(string: str): return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHU4CgxQIyqa"
      },
      "source": [
        "remove_char = \"“”\" + string.printable\n",
        "\n",
        "def clean_text(text: str) -> str:  \n",
        "    # Remove Hashtag\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # Remove twitter tag like @Nuttee\n",
        "    text = re.sub(\"/(^|[^@\\w])@(\\w{1,15})\\b/\", \"\", text)\n",
        "\n",
        "    # Remove emoji\n",
        "    text = remove_emoji(text)\n",
        "    \n",
        "    # Remove some weird character and english alphabet\n",
        "    return text.translate(str.maketrans('', '', remove_char))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4YX5orZu3s1"
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus import common\n",
        "from pythainlp.corpus import wordnet\n",
        "\n",
        "th_stop = common.thai_stopwords() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpYf8cw6p8D-"
      },
      "source": [
        "def split_word(text: str) -> list:\n",
        "    # tokenize text using pythainlp tokenizer\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # remove stop words\n",
        "    tokens = [i for i in tokens if not i in th_stop]\n",
        "    \n",
        "    # Find Stemword in Thai\n",
        "    tokens_temp = []\n",
        "    for i in tokens:\n",
        "        w_syn = wordnet.synsets(i)\n",
        "        if ( len(w_syn) > 0) and ( len( w_syn[0].lemma_names('tha') ) > 0 ):\n",
        "            tokens_temp.append( w_syn[0].lemma_names('tha')[0] )\n",
        "        else:\n",
        "            tokens_temp.append(i)\n",
        "    \n",
        "    tokens = tokens_temp\n",
        "    \n",
        "    # Delete blank space\n",
        "    tokens = [i for i in tokens if not ' ' in i]\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "cVvcz0d-yuxq",
        "outputId": "e211ebf8-d5a9-476b-b4d8-7aa7a8506089"
      },
      "source": [
        "# Clean text\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "# Split it\n",
        "df['text'] = df['text'].apply(split_word)\n",
        "\n",
        "df.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>is_spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>กก ต จี้ อนาคต แจง เงินกู้ ธนา ธร</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ตาย สนิท อิศรา ภงด ปี ช่อ แจ้ง รายได้ แสน คืน ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ชีวิต ติด ใบแดง กันต์ ธีร ์ ข้อมูล</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>อ้าว เฮ้ย เหมือน คุย หว่า อุตส่าห์ รณรงค์ ยกเล...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เป้ น กำลังใจ ท่าน</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4819</th>\n",
              "      <td>ทําไม รอ พุธ ดู</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>ฮะ ทําไม</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4821</th>\n",
              "      <td>ห้าง เอสพลานาด บ้าน ไหม อ่ะ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4822</th>\n",
              "      <td>น่าเสียดาย อารมณ์ แนะ ไหม</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4823</th>\n",
              "      <td>ชาย คน ตัว รํา คา ญ ฉันท ํา เหมือน สนใจ ที่จะ ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9624 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  is_spam\n",
              "0                     กก ต จี้ อนาคต แจง เงินกู้ ธนา ธร        1\n",
              "1     ตาย สนิท อิศรา ภงด ปี ช่อ แจ้ง รายได้ แสน คืน ...        1\n",
              "2                    ชีวิต ติด ใบแดง กันต์ ธีร ์ ข้อมูล        1\n",
              "3     อ้าว เฮ้ย เหมือน คุย หว่า อุตส่าห์ รณรงค์ ยกเล...        1\n",
              "4                                    เป้ น กำลังใจ ท่าน        1\n",
              "...                                                 ...      ...\n",
              "4819                                    ทําไม รอ พุธ ดู        0\n",
              "4820                                           ฮะ ทําไม        0\n",
              "4821                        ห้าง เอสพลานาด บ้าน ไหม อ่ะ        0\n",
              "4822                          น่าเสียดาย อารมณ์ แนะ ไหม        0\n",
              "4823  ชาย คน ตัว รํา คา ญ ฉันท ํา เหมือน สนใจ ที่จะ ...        0\n",
              "\n",
              "[9624 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVRXKMjsxUZW"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHncgIxPtSa-"
      },
      "source": [
        "## Vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb035vnLeQ7U"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Split our data so that We can use it to train and test.\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(df['text'], df['is_spam'], test_size=0.3, random_state = 42)\n",
        "\n",
        "# Make the metrics fit with data first\n",
        "vectorizer.fit(features_train)\n",
        "\n",
        "# Transform our data\n",
        "features_train = vectorizer.transform(features_train)\n",
        "features_test = vectorizer.transform(features_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "786lRFaVn6ze"
      },
      "source": [
        "## GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y9Qbuo0jSsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350854b6-2769-4625-ba16-cc38c7fcf5da"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Create an instance for our model\n",
        "gnb = GaussianNB()\n",
        "# Train it with our data\n",
        "gnb.fit(features_train.toarray(), labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5bvbgJbmKN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb7d122-9c55-4382-b28e-e86c70bd6739"
      },
      "source": [
        "# See how well is it doing\n",
        "gnb_prediction = gnb.predict(features_test.toarray())\n",
        "print(\"Accuracy Score:\", accuracy_score(labels_test, gnb_prediction))\n",
        "\n",
        "print(classification_report(labels_test, gnb_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.800207756232687\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83      1445\n",
            "           1       0.94      0.64      0.76      1443\n",
            "\n",
            "    accuracy                           0.80      2888\n",
            "   macro avg       0.83      0.80      0.80      2888\n",
            "weighted avg       0.83      0.80      0.80      2888\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qi1iUTPxYTv"
      },
      "source": [
        "## Test it by yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruaiUg3mfEe0"
      },
      "source": [
        "# We can try testing our model here\n",
        "\n",
        "while True:\n",
        "  try: s1 = clean_text(input(\"Input Message: \"))  # We will clean it here\n",
        "  except KeyboardInterrupt: break # Prevent traceback  \n",
        "\n",
        "  # Transform it first\n",
        "  s = vectorizer.transform([split_word(s1)])\n",
        "  # Let see the prediction\n",
        "  # Except for blank text, We will just ignore that\n",
        "  is_io = gnb.predict( s.toarray() )[0] == 1 if s1.strip() != \"\" else False\n",
        "  \n",
        "  print(\"Is IO:\", is_io )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}